- Other ways to detect dark matter?

- Other motivation for SUSY (CP violation, Sakharov, GUT)

- Why is important that pseudorapidity intervals are invariant:

  The momentum of the parton is not known. Two partons colliding in opposite
  directions can have any range of momentum from 0 to the sum of the momenta
  they had so the (spread along z axis... elaborate)

- What is a PV and a secondary vertex?

- What cosmological measurements have been made that suggest that the content
  of visible matter in the universe is just 5\%?

- Can you explain all the terms in the luminosity formula?

  The number of particles per bunch is squared because we have two bunches and
  this represents the possbile interactions of a buch containing N protons with
  another bunch containing N protons. The revolution frequency can be
  calculated dividing the speed of light by the LHC circumference obtaining \sim
  11~kHz. The crossing angle is given by:

  one beam pipe
  -------\    /--------
          \  /
           \/ This is F
           /\
          /  \
  -------/    \--------
  second beam pipe

  The beam emittance \epsilon is the spread of the bunch as a function of the
  momentum. On a x-p plane is an elipses. The \beta function is the function
  that describe the oscillation of the bunch due to the centripetal force and
  the magnet that pulls it towards the center of the LHC.

- Give an example of homogeneous calorimeter, what are the benefits?

- Why LAr has an accordion shape, why we use LAr?

- Why TileCal in barrel and LAr in forward regions?

  LAr technology is radiation resistant while the scintillators tend to give
  less light after some time spent in a high radiation environment.

- How to measure absolute luminosity?

- Strenghts and weaknesses of ATLAS and CMS

- Why neutrinos cannot be dark matter candidates?

  Can deduct the kinematic of particles from temperature. Neturino masses are
  small and thus they have a lot of kinetic energy (from the big bang), from
  simulations it can be seen that the gravitational pull is not enough to bound
  them in galaxies thus we need something heavier than neutrinos.

- How can we generate so much MC events to simulate for all the data we collect?

  We generate selected processes with smaller cross sections and not the whole
  possibles pp collision outcomes.

- Why some group chose a set of working points (jvt)

  Its a compromise between efficiency and purity of samples. Generally more than
  one working point is provided to accomodate the need of all the different
  analysis.

- The difference between different MC generators?

  They have different hadronization models (empirical because qcd is not
  perturbative anymore at the energy scale when quarks and gluons hadronize).

- How does SCT measure the PV and secondary vertex? Is what they really do
  directly or is done indirectly? How?

- Why there is no excess in the high met at 13 TeV? Is it because at 8 TeV was
  just a fluctuation? Is it because of the increased energy?

- Why do you think you have contributed enough for a PhD?

- What do your different models solve and not solve, with respect to the SM
  problems you have formulated in chapter 1? How do your limits play into that?

- Why do you quote neutrino masses for the flavor eigenstates?

- How do you give masses to the neutrinos?

- Is there more physics predicted from the ADD model? Do we expect other
  particles?

- Is the diphoton excess compatible with a graviton model? With your graviton
  model?

- In the CR fit is the agreement between data and MC good also before fit? Why
  don't we rely directly on the MC cross sections?

- Why don't we use pure theoretical cross section but need the data driven
  method? What are the limitations of the different MC generators? Why aren't
  they perfect or good enough?

- What is the order of the V + jets simulation, LO, NLO? Up to how many partons?

- Why do we chose this normalization scheme for the transfer factors?

- How is the jet response function derived?

- Why the inverted \delta \phi min cut can make a multi--jet control region?

- How are we sure that the events selected in the way described in the NCB
  section come from BIB?

- What is the jet energy scale and how the resolution contributes to the
  systematic uncertainties?

- How is the luminosity actually measured and calculated?

- Why are the expected limits getting a bit worse for higher mass gaps (25 GeV)?

- What is a prompt electron?

- Is the same likelihood used for all electrons eta and ET but with different
  cuts in different eta and ET or are you actually using a different likelihood
  function in the different bins? It seems to me the later would be better.

- What is a local track segment?

- How is the pile--up correction for jets performed?

- How do you classify the energy deposits as electromagnetic or hadronic?

- How is the tight criterion for jets defined?

- Why most systematic uncertainties cancel out with the data driven method?

- Why are we even doing monophotons when monojet always provides better
  sensitivity?

- Why do the DM plots look the way they do? Eg. why do the sensitivity go to
  zero at low wimp mass, and decrease again for high wimp masses? Do all these
  experiments make the same assumptions?

- What is an axial-vector mediator?

- Does SUSY solve naturalness at the current limits?

- What is naturalness good for? Seeing that it motivates most of your
  searches. Has naturalness ever motivated a discovery before?

- Can you get the proper relic density with neutralinos? With UED? With
  gravitinos?

- Is the graviton interaction really an effective interaction? The Feynman
  diagrams donâ€™t look that way.

- What is a general-purpose detector? Can it make coffee? (Here I think the
  answer is yes, but you would probably not want to drink it)

- How do the new LVPS affect other things? Such as for example the timing?

- Is the non-iterative OF a lot worse in terms of performance than the
  iterative?

- Why can you not create b or c quarks in hadronization?

- Why does our 8 TeV trigger plateau earlier than the 13 TeV trigger?

- How do we actually measure the efficiency of a trigger?

- Why did we increase the number of jets from the 7 TeV analysis?

- When is it better to use one region and not a multi-region fit?

- Why do we use renorm and fact scale times 0.5 and 2 for systematics?

- How do we determine how many events to generate?

- The Pythia settings - are they tested on SM physics so we know what to expcect
  for radiation?

- What is the pros and cons for the two different ways of estimating the top
  systematics?

- What are the pros and cons of BLUE vs the Likelihood metod?

- Your control regions in the 8 TeV analysis clearly perform worse at high
  MET. Why should we then trust the background estimate at high MET? And do you
  understand why you had this problem at 8 TeV and not at 13 TeV?

%% From Olle's PhD defence

- What happens if the energy deposit is less than 2 (like 1.8 \sigma), does this
  cell gets clustered as well?

- Is there other physical correlation to noise other than the vicinity to LVPS
  that was observed (fig 4.4)?

- Do we still use the double Gaussian fit?

- Why and how can I trust the trunkation methos? All the events are used during
  the estimation and efficiency studies, how can you throw them out aftewards
  without affecting the estimation done before?

- The requirement of \met from 8 TeV to 13 TeV and also the efficiency changed,
  was because the trigger got better?

- The number of jets is an inclusive selection or an exclusie one? (do we always
  look for less than 4 jets or we require 1 or 2 or 3 jets?)

- Why was the Z \to ee region dropped in favor of the Z \to nu nu?

- Why in the 13 TeV the pile up weight is not used?

- Why is the \Gamma so different from m_0 in table 8.1?

- Why you cut on \met and \Delta \phi exclusively, wouldn't be better cut
  simultaneously on both? (fig. 9.2)

- How do you see the evolution of this search in the next three years? What can
  be done to improve the mesurement?

- What if ATLAS finds something in a region already excluded by a direct
  detection experiment like Ice Cube, how would you reconcile the results?

- How do you tell apart all the different signals that we are probing with the
  monojet signature in case of an excess?
